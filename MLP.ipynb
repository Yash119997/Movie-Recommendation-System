{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zI6SYqvC56OJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, zero_one_loss, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BkCFmKE56OO",
    "outputId": "72bd7fdf-e0a7-40b4-a1e8-aed60d422013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UTgcwECb56OP"
   },
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "\n",
    "# (60K: Train) and (10K: Test)\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JVs2x-QZ56OQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-Z2D37K556OQ"
   },
   "outputs": [],
   "source": [
    "mlp1 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=0.0001)\n",
    "#sgd refers to stochastic gradient descent.\n",
    "mlp1.fit(X_train, y_train)\n",
    "y_pred = mlp1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdiqfzor56OR",
    "outputId": "31f25b4e-5106-4475-a58b-a598f47d1b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.97      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Accuracy: 0.9785\n",
      "Error: 0.021499999999999964\n"
     ]
    }
   ],
   "source": [
    "print(\"Report: \" + str(classification_report(y_test, y_pred)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4kzao8C56OS",
    "outputId": "eac211ad-8c6f-483b-e42d-06de3b2af80c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.90      0.91      1032\n",
      "           3       0.90      0.92      0.91      1010\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.90      0.87      0.88       892\n",
      "           6       0.94      0.95      0.95       958\n",
      "           7       0.93      0.92      0.92      1028\n",
      "           8       0.88      0.89      0.88       974\n",
      "           9       0.91      0.91      0.91      1009\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Accuracy: 0.9235\n",
      "Error: 0.07650000000000001\n"
     ]
    }
   ],
   "source": [
    "# For lbfgs solver:\n",
    "# 50 hidden layers, activation function is identity, learning rate is set to constant and max iterations is set to 450 \n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(50), activation='identity', solver='lbfgs', alpha=0.001, \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              max_iter=450, tol=0.00001, \n",
    "              validation_fraction=0.2, beta_1=0.9, beta_2=0.999, \n",
    "              max_fun=15000)\n",
    "\n",
    "mlp2.fit(X_train, y_train)\n",
    "y_pred2 = mlp2.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred2)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred2)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tdCkGfB56OT",
    "outputId": "f6e3d66f-ed4d-4eae-affb-0ca95e918468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.97      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.96      0.96      0.96       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "Accuracy: 0.9709\n",
      "Error: 0.029100000000000015\n"
     ]
    }
   ],
   "source": [
    "# For lbfgs solver:\n",
    "# 100 hidden layers, activation function is logistic, learning rate is set to adaptive, \n",
    "# beta1 is 0.95 and max iterations is set to 500 \n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='lbfgs', alpha=0.001, \n",
    "              learning_rate='adaptive', learning_rate_init=0.001, \n",
    "              max_iter=500, tol=0.00001, \n",
    "              validation_fraction=0.2, beta_1=0.95, beta_2=0.999, \n",
    "              max_fun=15000)\n",
    "\n",
    "mlp3.fit(X_train, y_train)\n",
    "y_pred3 = mlp3.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred3)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred3)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4MDFWYM56OT",
    "outputId": "d556d993-c8bb-4bbf-aa5d-ff99a46210a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.97      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.98      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Accuracy: 0.9791\n",
      "Error: 0.02090000000000003\n"
     ]
    }
   ],
   "source": [
    "# For lbfgs solver:\n",
    "# 200 hidden layers, activation function is relu, learning rate is set to invscaling, beta1 is 0.9 and max iterations is set to 550 \n",
    "mlp4 =  MLPClassifier(hidden_layer_sizes=(200), activation='relu', solver='lbfgs', alpha=0.001, \n",
    "              learning_rate='invscaling', learning_rate_init=0.01, \n",
    "              max_iter=550, tol=0.00001, \n",
    "              validation_fraction=0.2, beta_1=0.9, beta_2=0.999, \n",
    "              max_fun=15000)\n",
    "\n",
    "mlp4.fit(X_train, y_train)\n",
    "y_pred4 = mlp4.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred4)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred4)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAMXGELo56OU",
    "outputId": "d9a56e0d-392b-4f1d-c5e2-78efca6dfb33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.94      0.96      0.95      1010\n",
      "           4       0.95      0.96      0.95       982\n",
      "           5       0.96      0.93      0.94       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.95      0.94      0.94       974\n",
      "           9       0.94      0.93      0.94      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n",
      "Accuracy: 0.9541\n",
      "Error: 0.04590000000000005\n"
     ]
    }
   ],
   "source": [
    "# For sgd solver:\n",
    "# 50 hidden layers, activation function is logistic, learning rate is set to constant, batch size is auto\n",
    "# epochs is set to 10 and max iterations is set to 500 \n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(50), activation='logistic', solver='sgd', alpha=0.001, \n",
    "              batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter = 500,\n",
    "              tol=0.0001, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, n_iter_no_change=10)\n",
    "\n",
    "mlp5.fit(X_train, y_train)\n",
    "y_pred5 = mlp5.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred5)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred5)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WGE_qHy56OV",
    "outputId": "86bb36be-5e97-4300-8193-5764f7ee0dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59241646\n",
      "Validation score: 0.894333\n",
      "Iteration 2, loss = 0.36175796\n",
      "Validation score: 0.896500\n",
      "Iteration 3, loss = 0.36016917\n",
      "Validation score: 0.896167\n",
      "Iteration 4, loss = 0.35933324\n",
      "Validation score: 0.896167\n",
      "Iteration 5, loss = 0.35878133\n",
      "Validation score: 0.896167\n",
      "Iteration 6, loss = 0.35837312\n",
      "Validation score: 0.896167\n",
      "Iteration 7, loss = 0.35804900\n",
      "Validation score: 0.896000\n",
      "Iteration 8, loss = 0.35778327\n",
      "Validation score: 0.895833\n",
      "Iteration 9, loss = 0.35755356\n",
      "Validation score: 0.896000\n",
      "Iteration 10, loss = 0.35735198\n",
      "Validation score: 0.895833\n",
      "Iteration 11, loss = 0.35717199\n",
      "Validation score: 0.895833\n",
      "Iteration 12, loss = 0.35700865\n",
      "Validation score: 0.895667\n",
      "Iteration 13, loss = 0.35685820\n",
      "Validation score: 0.895667\n",
      "Iteration 14, loss = 0.35671876\n",
      "Validation score: 0.895833\n",
      "Iteration 15, loss = 0.35658746\n",
      "Validation score: 0.895833\n",
      "Iteration 16, loss = 0.35646395\n",
      "Validation score: 0.895833\n",
      "Iteration 17, loss = 0.35634755\n",
      "Validation score: 0.895833\n",
      "Iteration 18, loss = 0.35623579\n",
      "Validation score: 0.896000\n",
      "Iteration 19, loss = 0.35612942\n",
      "Validation score: 0.896000\n",
      "Iteration 20, loss = 0.35602729\n",
      "Validation score: 0.896000\n",
      "Iteration 21, loss = 0.35592932\n",
      "Validation score: 0.895667\n",
      "Iteration 22, loss = 0.35583474\n",
      "Validation score: 0.895667\n",
      "Iteration 23, loss = 0.35574279\n",
      "Validation score: 0.895667\n",
      "Validation score did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       980\n",
      "           1       0.96      0.97      0.97      1135\n",
      "           2       0.91      0.88      0.89      1032\n",
      "           3       0.91      0.88      0.89      1010\n",
      "           4       0.90      0.92      0.91       982\n",
      "           5       0.87      0.86      0.86       892\n",
      "           6       0.93      0.93      0.93       958\n",
      "           7       0.92      0.90      0.91      1028\n",
      "           8       0.85      0.88      0.86       974\n",
      "           9       0.88      0.88      0.88      1009\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n",
      "Accuracy: 0.9064\n",
      "Error: 0.09360000000000002\n"
     ]
    }
   ],
   "source": [
    "# For sgd solver:\n",
    "# 100 hidden layers, activation function is tanh, learning rate is set to invscaling, batch size is auto\n",
    "# epochs is set to 20 and max iterations is set to 500 \n",
    "mlp6 = MLPClassifier(hidden_layer_sizes=(100), activation='tanh', solver='sgd', alpha=0.001, \n",
    "              batch_size='auto', learning_rate='invscaling', learning_rate_init=0.01, power_t=0.5,\n",
    "              tol=0.0001, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "              verbose = 10, early_stopping=True, max_iter=500, n_iter_no_change=20)\n",
    "\n",
    "mlp6.fit(X_train, y_train)\n",
    "y_pred6 = mlp6.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred6)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred6)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e538AsBg56OV",
    "outputId": "6c90c406-f439-4c92-a714-eaa3f6e137db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.98      0.98      1032\n",
      "           3       0.98      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Accuracy: 0.9786\n",
      "Error: 0.021399999999999975\n"
     ]
    }
   ],
   "source": [
    "# For sgd solver:\n",
    "# 200 hidden layers, activation function is relu, learning rate is set to adaptive , batch size is auto\n",
    "# epochs is set to 20, early stopping is used and max iterations is set to 550 \n",
    "mlp7 = MLPClassifier(hidden_layer_sizes=(200), activation='relu', solver='sgd', \n",
    "                     alpha=0.0001, batch_size='auto', learning_rate='adaptive', \n",
    "                     learning_rate_init=0.001, power_t=0.5, max_iter=550, tol=0.0001, early_stopping=True,\n",
    "                     validation_fraction=0.1, beta_1=0.9, beta_2=0.999, n_iter_no_change=20)\n",
    "\n",
    "mlp7.fit(X_train, y_train)\n",
    "y_pred7 = mlp7.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred7)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred7)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB1uE8oO56OW",
    "outputId": "8777e37a-fca4-4084-f942-3d160d761d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.97      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.97      0.97       892\n",
      "           6       0.99      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Accuracy: 0.9794\n",
      "Error: 0.02059999999999995\n"
     ]
    }
   ],
   "source": [
    "# For adam solver:\n",
    "# 250 hidden layers, activation function is logistic, learning rate is set to invscaling, batch size is auto\n",
    "# epochs is set to 20, early stopping is used and max iterations is set to 450 \n",
    "mlp8 = MLPClassifier(hidden_layer_sizes=(250), activation='logistic', solver='adam', alpha=0.0001, \n",
    "              learning_rate='invscaling', learning_rate_init=0.001, \n",
    "              max_iter=450, tol=0.0001, early_stopping=True,\n",
    "              validation_fraction=0.1, beta_1=0.95, beta_2=0.999, \n",
    "              n_iter_no_change=20)\n",
    "\n",
    "mlp8.fit(X_train, y_train)\n",
    "y_pred8 = mlp8.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred8)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred8)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhBp2DZI56OW",
    "outputId": "1eb3c9a5-c4eb-4e99-dad4-592d7f064a6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.97      0.98      0.97      1010\n",
      "           4       0.97      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.97      0.98      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "Accuracy: 0.9778\n",
      "Error: 0.022199999999999998\n"
     ]
    }
   ],
   "source": [
    "# For adam solver:\n",
    "# 250 hidden layers, activation function is tanh, learning rate is set to adaptive, \n",
    "# epochs is set to 20, early stopping is used and max iterations is set to 550 \n",
    "mlp9 = MLPClassifier(hidden_layer_sizes=(250), activation='tanh', solver='adam', alpha=0.0001, \n",
    "              learning_rate='adaptive', learning_rate_init=0.001, \n",
    "              max_iter=550, tol=0.0001, early_stopping=True,\n",
    "              validation_fraction=0.1, beta_1=0.95, beta_2=0.999, \n",
    "              n_iter_no_change=20)\n",
    "\n",
    "mlp9.fit(X_train, y_train)\n",
    "y_pred9 = mlp9.predict(X_test)\n",
    "\n",
    "print(\"Report: \" + str(classification_report(y_test, y_pred9)))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test,y_pred9)))\n",
    "print(\"Error: \" + str(zero_one_loss(y_test, y_pred9)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
