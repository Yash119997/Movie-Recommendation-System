{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pass in column names for each CSV as the column name is not given in the file and read them using pandas.\n",
    "# # You can check the column names from the readme file\n",
    "# #Reading users file:\n",
    "\n",
    "# users = pd.read_csv(r'C:\\Users\\Yash\\Documents\\0_ML\\0_HW\\hw2\\netflix\\TrainingRatings.txt', names=cols, sep='|', encoding='latin-1')\n",
    "\n",
    "# cols2 = ['MovieID' ,'YearOfRelease' ,'Title']\n",
    "# items = pd.read_csv(r'C:\\Users\\Yash\\Documents\\0_ML\\0_HW\\hw2\\netflix\\movie_titles.txt', names=cols2, sep='|',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = training.UserID.unique().shape[0]\n",
    "n_items = training.MovieID.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in training.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_movie_features.replace(0, np.nan, inplace=True)\n",
    "# df_movie_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_movies = df_movie_features.fillna(df_movie_features.mean(axis=0))\n",
    "# final_movies\n",
    "# final_user = df_movie_features.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "# final_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user similarity on replacing NAN by user avg\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "b = cosine_similarity(final_user)\n",
    "np.fill_diagonal(b, 0 )\n",
    "similarity_with_user = pd.DataFrame(b,index=final_user.index)\n",
    "similarity_with_user.columns=final_user.index\n",
    "similarity_with_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user similarity on replacing NAN by user avg\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "b = cosine_similarity(final_user)\n",
    "np.fill_diagonal(b, 0 )\n",
    "similarity_with_user = pd.DataFrame(b,index=final_user.index)\n",
    "similarity_with_user.columns=final_user.index\n",
    "similarity_with_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user similarity on replacing NAN by item(movie) avg\n",
    "cosine = cosine_similarity(final_movies)\n",
    "np.fill_diagonal(cosine, 0 )\n",
    "similarity_with_movie = pd.DataFrame(cosine,index=final_movies.index)\n",
    "similarity_with_movie.columns=final_user.index\n",
    "similarity_with_movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_neighbours(df,n):\n",
    "    order = np.argsort(df.values, axis=1)[:, :n]\n",
    "    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
    "           .iloc[:n].index, \n",
    "          index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 30 neighbours for each user\n",
    "sim_user_30_u = find_n_neighbours(similarity_with_user,10)\n",
    "sim_user_30_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line in training[:3].itertuples():\n",
    "#     print(line)\n",
    "#     print(line[1], line[2], line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_matrix = np.zeros((n_users.shape[0]-1, n_items.shape[0]-1))\n",
    "# for line in training.itertuples():\n",
    "#     train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "\n",
    "# test_data_matrix = np.zeros((n_users, n_items))\n",
    "# for line in testing.itertuples():\n",
    "#     test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(df_movie_features, cos_df, type='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrMatrix = df_movie_features.corr(method='pearson')\n",
    "# corrMatrix.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim_users = sorted(list(enumerate(cos_df[8])), key=lambda x: x[1], reverse=True)\n",
    "most_sim_users = most_sim_users[1:11]\n",
    "sim_users = [x[0] for x in most_sim_users]\n",
    "print(sim_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(ele):\n",
    "    return ele[1]\n",
    "\n",
    "def predict(userId, movieId):\n",
    "    dict_with_rating = {}\n",
    "    lis = []\n",
    "    for idx, rating in enumerate(df_movie_features.iloc[movieId - 1]):\n",
    "        if(rating > 0):\n",
    "            temp = (idx,rating)\n",
    "            dict_with_rating[idx] = rating\n",
    "            lis.append(temp)\n",
    "    top_k = []\n",
    "    for i,sim in enumerate(cos_df.iloc[userId - 1]):\n",
    "        for j,k in lis:\n",
    "            if(j == i):\n",
    "                top_k.append([i,sim])\n",
    "    top_sorted_sim = sorted(top_k, key=cos_df.iloc[userId], reverse=True)\n",
    "    top_5 = top_sorted_sim[:5]\n",
    "    sum_ = 0\n",
    "    sim_sum = 0\n",
    "    for top in top_5:\n",
    "        sum_ += dict_with_rating[top[0]]*top[1]\n",
    "        sim_sum += top[1]\n",
    "    return sum_ / sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = training.UserID\n",
    "movie_id = training.MovieID \n",
    "rating_s = training.Rating\n",
    "\n",
    "ui_train, ui_test, mi_train, mi_test, r_train, r_test = train_test_split(user_id, movie_id, rating_s, test_size=0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ui_test.shape)\n",
    "print(mi_test.shape)\n",
    "print(r_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_list = []\n",
    "for j in range(28978):\n",
    "    predicted_rats = predict(ui_test.iloc[j], mi_test.iloc[j])\n",
    "    rating_Q = r_test.iloc[j]\n",
    "    half_rmse = (predicted_rats - rating_Q)**2\n",
    "    em_list.append(half_rmse)\n",
    "rmse = math.sqrt(sum(em_list)/len(em_list))\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_corelation(person1,person2):\n",
    "    both_rated = {}\n",
    "    for item in training[person1]:\n",
    "        if item in training[person2]:\n",
    "            both_rated[item] = 1\n",
    "\n",
    "    number_of_ratings = len(both_rated)\n",
    "    if number_of_ratings == 0:\n",
    "        return 0\n",
    "\n",
    "    person1_preferences_sum = sum([training[person1][item] for item in both_rated])\n",
    "    person2_preferences_sum = sum([training[person2][item] for item in both_rated])\n",
    "\n",
    "    # Sum up the squares of preferences of each user\n",
    "    person1_square_preferences_sum = sum([pow(training[person1][item], 2) for item in both_rated])\n",
    "    person2_square_preferences_sum = sum([pow(training[person2][item], 2) for item in both_rated])\n",
    "\n",
    "    # Sum up the product value of both preferences for each item\n",
    "    product_sum_of_both_users = sum([training[person1][item] * training[person2][item] for item in both_rated])\n",
    "\n",
    "    # Calculate the pearson score\n",
    "    numerator_value = product_sum_of_both_users - (\n",
    "    person1_preferences_sum * person2_preferences_sum / number_of_ratings)\n",
    "    denominator_value = sqrt((person1_square_preferences_sum - pow(person1_preferences_sum, 2) / number_of_ratings) * (\n",
    "    person2_square_preferences_sum - pow(person2_preferences_sum, 2) / number_of_ratings))\n",
    "    if denominator_value == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        r = numerator_value / denominator_value\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_factor(x, y):\n",
    "    ''' \n",
    "    Weight factor implies relationship between user x and user y\n",
    "    Also know as similarity between user x and user y\n",
    "    We are using Pearson correlation coefficient here. \n",
    "    '''    \n",
    "    t1, t2, t3 = 0, 0, 0 \n",
    "    for i, j in zip(x, y):\n",
    "        t1+=i*j\n",
    "        t2+=i*i\n",
    "        t3+=j*j\n",
    "    return t1/(np.sqrt(t2) * np.sqrt(t3))\n",
    "\n",
    "n = 1000\n",
    "active_user_id = training.iloc[n, 0]\n",
    "\n",
    "active_user = training[training['UserID'] == active_user_id]\n",
    "active_user_rating = active_user.iloc[:, 2:]\n",
    "active_user_rating\n",
    "\n",
    "# saving active user ratings into 1 d list\n",
    "active_user_rating_list = active_user_rating.values.ravel()\n",
    "# finding similarity between active user and all its neighbours among complete rating users\n",
    "similarity = np.array([(training.iloc[i, 0],\\\n",
    "             weight_factor(active_user_rating_list, training.iloc[i, 2:]))\\\n",
    "             for i in range(training.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt \n",
    "def calcSim (user, userOther, data):\n",
    "    sum_xy = 0\n",
    "    sum_x2 = 0\n",
    "    sum_y2 = 0\n",
    "    n = 0\n",
    "    rating1 = data[user]\n",
    "    rating2 = data[userOther]\n",
    "\n",
    "    for key in rating1.all()>0:\n",
    "        if key in rating2>0:\n",
    "            n += 1\n",
    "            sum_xy += rating1[key]*rating2[key]\n",
    "\n",
    "\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "\n",
    "        for value in rating1[:]:\n",
    "            sum_x2 += value**2\n",
    "        for value in rating2[:]:\n",
    "            sum_y2 += value**2\n",
    "\n",
    "        denominator = sqrt(sum_x2) * sqrt(sum_y2)\n",
    "\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return sum_xy/denominator\n",
    "\n",
    "calcSim(1,2,train_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function finds k similar users given the user_id and ratings matrix M\n",
    "#Note that the similarities are same as obtained via using pairwise_distances\n",
    "global k,metric\n",
    "k=4\n",
    "metric='correlation'\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def findksimilarusers(user_id, ratings, metric = metric, k=k):\n",
    "    similarities=[]\n",
    "    indices=[]\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute') \n",
    "    model_knn.fit(ratings)\n",
    "    txt = '{0} most similar users for User {1}:\\n'\n",
    "    print(txt.format(k,UserID))\n",
    "    distances, indices = model_knn.kneighbors(ratings[user_id-1, :].reshape(1, -1), n_neighbors = k+1)\n",
    "    similarities = 1-distances.flatten()\n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i]+1 == user_id:\n",
    "            continue;\n",
    "            \n",
    "    return similarities,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities,indices = findksimilarusers(7,train_data_matrix, metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function predicts rating for specified user-item combination based on user-based approach\n",
    "def predict_userbased(user_id, item_id, ratings, metric = metric, k=k):\n",
    "    prediction=0\n",
    "    similarities, indices=findksimilarusers(user_id, ratings,metric, k) #similar users based on cosine similarity\n",
    "    mean_rating = ratings[user_id-1,:].mean() #to adjust for zero based indexing\n",
    "    sum_wt = np.sum(similarities)-1\n",
    "    product=1\n",
    "    wtd_sum = 0 \n",
    "    \n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i]+1 == user_id:\n",
    "            continue;\n",
    "        else: \n",
    "            ratings_diff = ratings[indices.flatten()[i],item_id-1]-np.mean(ratings[indices.flatten()[i],:])\n",
    "            product = ratings_diff * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product\n",
    "    \n",
    "    prediction = int(round(mean_rating + (wtd_sum/sum_wt)))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predict_userbased(7,8,train_data_matrix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
